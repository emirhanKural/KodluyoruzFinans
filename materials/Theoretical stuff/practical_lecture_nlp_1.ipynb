{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"},"colab":{"name":"practical_lecture_nlp_1.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"UjlYPfTK2LAL"},"source":["from sklearn.linear_model import LogisticRegression\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from tqdm import tqdm_notebook\n","from sklearn.feature_extraction.text import CountVectorizer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WksKxjH_2LAX"},"source":["# Sentiment Analysis Using IMDb dataset"]},{"cell_type":"markdown","metadata":{"id":"azZTyU812LAY"},"source":["* Sentiment analysis is about classification of the polarity of a given text"]},{"cell_type":"markdown","metadata":{"id":"xR_8HtmH2LAa"},"source":["* write those command at linux bash:\n","\n","wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","\n","gunzip aclImdb_v1.tar.gz\n","\n","tar -xvf aclImdb_v1.tar"]},{"cell_type":"markdown","metadata":{"id":"vrEDaIUe2LAc"},"source":["## Creating Dataset"]},{"cell_type":"code","metadata":{"id":"4ONjg_ek2LAd"},"source":["from pathlib import Path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jAcUlPiv2LAk"},"source":["import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sYOuZTI02LAq"},"source":["PATH= Path('data/aclImdb/')\n","names = ['neg','pos']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MJITUhun2LAx","outputId":"f8e0657f-48b1-42a5-d169-96233e822baf"},"source":["PATH/\"val\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["WindowsPath('data/aclImdb/val')"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"eT3BS74v2LA4"},"source":["### Adding Custom Made Method"]},{"cell_type":"code","metadata":{"id":"lrjE9lSb2LA5"},"source":["Path.ls = lambda x: list(x.iterdir())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_qf7x6Oi2LBA","outputId":"b908259a-a2be-4ef4-d9d0-56ab87334f86"},"source":["PATH.ls()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[WindowsPath('data/aclImdb/imdb.vocab'),\n"," WindowsPath('data/aclImdb/imdbEr.txt'),\n"," WindowsPath('data/aclImdb/README'),\n"," WindowsPath('data/aclImdb/test'),\n"," WindowsPath('data/aclImdb/train')]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"9FjiX3b62LBG"},"source":["a = PATH/\"train\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"75KrPXKr2LBJ","outputId":"09caf491-8c75-4955-863e-470ed381d240"},"source":["a"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["WindowsPath('data/aclImdb/train')"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"2oHG9IqT2LBO"},"source":["### scandir()"]},{"cell_type":"markdown","metadata":{"id":"NMPsb2-O2LBP"},"source":["* This will give us the list of files in the path that we have given "]},{"cell_type":"code","metadata":{"id":"j4gasUG62LBP","outputId":"288b4616-a6f3-4ba9-e6d6-b62a7dc3410b"},"source":["list(os.scandir('data/aclImdb/train'))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<DirEntry 'labeledBow.feat'>,\n"," <DirEntry 'neg'>,\n"," <DirEntry 'pos'>,\n"," <DirEntry 'unsup'>,\n"," <DirEntry 'unsupBow.feat'>,\n"," <DirEntry 'urls_neg.txt'>,\n"," <DirEntry 'urls_pos.txt'>,\n"," <DirEntry 'urls_unsup.txt'>]"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"xGdD2GjC2LBX","outputId":"7f762306-b00e-44ac-8a20-254d733431b3"},"source":["list(os.scandir(a))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<DirEntry 'labeledBow.feat'>,\n"," <DirEntry 'neg'>,\n"," <DirEntry 'pos'>,\n"," <DirEntry 'unsup'>,\n"," <DirEntry 'unsupBow.feat'>,\n"," <DirEntry 'urls_neg.txt'>,\n"," <DirEntry 'urls_pos.txt'>,\n"," <DirEntry 'urls_unsup.txt'>]"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"G6A7Jc2T2LBc"},"source":["### iterdir()"]},{"cell_type":"markdown","metadata":{"id":"gZzQsnQ32LBe"},"source":["* This will give us the list of paths of the files in the path that we have given "]},{"cell_type":"code","metadata":{"id":"zKxrVvxt2LBf","outputId":"f6f38c7a-094e-4b9c-c7b8-dab439c5de3e"},"source":["a.iterdir()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<generator object Path.iterdir at 0x0000029B8402E648>"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"xALYVwED2LBl","outputId":"a2da4a78-3ef2-42d5-c18b-7cf55f01b927"},"source":["list(a.iterdir())"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[WindowsPath('data/aclImdb/train/labeledBow.feat'),\n"," WindowsPath('data/aclImdb/train/neg'),\n"," WindowsPath('data/aclImdb/train/pos'),\n"," WindowsPath('data/aclImdb/train/unsup'),\n"," WindowsPath('data/aclImdb/train/unsupBow.feat'),\n"," WindowsPath('data/aclImdb/train/urls_neg.txt'),\n"," WindowsPath('data/aclImdb/train/urls_pos.txt'),\n"," WindowsPath('data/aclImdb/train/urls_unsup.txt')]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"tEmy_0hL2LBq"},"source":["### Writing function to get specific file format"]},{"cell_type":"code","metadata":{"id":"eCYRGtq_2LBr"},"source":["def _get_files(p, fs, extensions = None):\n","    p = Path(p)\n","    res = [p/f for f in fs if not f.startswith(\".\") \n","           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n","    return res"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zGCYtCMs2LBx"},"source":["### Creating Dataset from File"]},{"cell_type":"code","metadata":{"id":"wZ4Owenp2LBy"},"source":["def create_ds_from_file(src, names):\n","    texts, labels = [], []\n","    \n","    for idx, name in enumerate(names):\n","        path = src/name\n","        print(path)\n","        t = [o.name for o in os.scandir(path)]\n","        t = _get_files(path, t, extensions = [\".txt\"])\n","        for e in t:\n","            l = [open(e).read().strip()]\n","            texts += l\n","        labels += ([idx] * len(t))\n","    return texts, np.array(labels) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z_abTPHp2LB4"},"source":["def create_ds_from_file(src, names):\n","    texts, labels = [], []\n","    \n","    for idx, name in enumerate(names):\n","        path = src/name\n","        print(path)\n","        t = [o.name for o in os.scandir(path)]\n","        t = _get_files(path, t, extensions = [\".txt\"])\n","        for e in t:\n","            l = [open(e, encoding=\"ISO-8859-1\").read().strip()]\n","            texts += l\n","        labels += ([idx] * len(t))\n","    return texts, np.array(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ele4_I6_2LB-"},"source":["### Creating our train and validation set"]},{"cell_type":"code","metadata":{"id":"-OG244q-2LB_","outputId":"b5e6b002-a533-498e-d889-777862f207bf"},"source":["trn_x, trn_y = create_ds_from_file(PATH/\"train\",names)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["data\\aclImdb\\train\\neg\n","data\\aclImdb\\train\\pos\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"Atd1EjSh2LCG","outputId":"9df0872e-7de7-47c5-80d7-ce060f420043"},"source":["val_x,val_y = create_ds_from_file(PATH/\"test\",names)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["data\\aclImdb\\test\\neg\n","data\\aclImdb\\test\\pos\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D2Yo-cK12LCJ"},"source":["* Here is the text of the first review in train set"]},{"cell_type":"code","metadata":{"id":"VbrovjVv2LCK","outputId":"ba0549b9-da7c-4859-d389-6ccbdf27133d"},"source":["trn_x[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\""]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"xXZ_OoWp2LCN"},"source":["* Label of the first review of training set"]},{"cell_type":"code","metadata":{"id":"VqTVPPh32LCO","outputId":"ef1ae76b-b182-4362-ea0a-75f527841bc0"},"source":["trn_y[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"dzhoMnPn2LCV","outputId":"934fd9ec-b1eb-4b96-db6e-36f3debf6797"},"source":["val_x[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.\""]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"ery0Cqjd2LCZ"},"source":["## Tokenizing"]},{"cell_type":"markdown","metadata":{"id":"PJ8M6rAQ2LCa"},"source":["In nlp we have to turn our text into list of words, and that process is called **Tokenization**"]},{"cell_type":"markdown","metadata":{"id":"n8pBY2Xk2LCb"},"source":["* But this is not a trivial task"]},{"cell_type":"markdown","metadata":{"id":"FsNFMstf2LCb"},"source":["* Like, if we have \"This movie isn't fun.\""]},{"cell_type":"markdown","metadata":{"id":"cBCYmDe82LCc"},"source":["* It should be like: This movie is n't fun ."]},{"cell_type":"markdown","metadata":{"id":"tlYqlHpr2LCd"},"source":["[`CountVectorizer`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) converts a collection of text documents to a matrix of token counts (part of `sklearn.feature_extraction.text`)."]},{"cell_type":"markdown","metadata":{"id":"s3dVHBwz2LCe"},"source":["### Creating Our Tokenizer"]},{"cell_type":"code","metadata":{"id":"rNkLsnoi2LCg"},"source":["import re\n","import string"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pXQTkAVt2LCm"},"source":["re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n","def tokenize(s): \n","    return re_tok.sub(r' \\1 ', s).split()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ca_XioDO2LCp"},"source":["vectorizer = CountVectorizer(tokenizer=tokenize)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IQ00b3UY2LCs"},"source":["* `fit_transform(trn)` creates the vocabulary from words in training set and it transforms the training set into a term-document matrix. "]},{"cell_type":"code","metadata":{"id":"GDQqLN1w2LCt"},"source":["trn_term_doc = vectorizer.fit_transform(trn_x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YSJC2cl92LCz"},"source":["* We have to apply the same transformation to our validation set"]},{"cell_type":"markdown","metadata":{"id":"N7pGZkI02LCz"},"source":["* This is just using vectorizer that is fitted to our training set"]},{"cell_type":"markdown","metadata":{"id":"a9ns8xWl2LC0"},"source":["* If there is an unseen word in validation set, it will fall into the unknown column"]},{"cell_type":"code","metadata":{"id":"nMqu1ERT2LC1"},"source":["val_term_doc = vectorizer.transform(val_x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lHo1a7s42LC6"},"source":["### Sparse Matrix"]},{"cell_type":"code","metadata":{"id":"qm6xvvgv2LC7","outputId":"2216e4a2-05e2-43cb-8fd0-d6dcffb5ab8d"},"source":["trn_term_doc"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<25000x75780 sparse matrix of type '<class 'numpy.int64'>'\n","\twith 3750614 stored elements in Compressed Sparse Row format>"]},"metadata":{"tags":[]},"execution_count":63}]},{"cell_type":"markdown","metadata":{"id":"LHqd5fjG2LDC"},"source":["* 25000x75780 : There are 25000 movie reviews, and there are 75780 unique words"]},{"cell_type":"markdown","metadata":{"id":"QL2tTXiG2LDD"},"source":["* Most documents won't have most of the 75780 words. So it will be very wasteful to store 25000x75780 into the memory."]},{"cell_type":"markdown","metadata":{"id":"XXrHA__V2LDD"},"source":["* We will store it as **sparse matrix**"]},{"cell_type":"markdown","metadata":{"id":"Kjp-eRMQ2LDE"},"source":["* There are different ways of storing sparse matrix but one method is like:\n","\n","* (1,4) -> 4 : document number 1, term number 4 appears 4 times\n","\n","* (3,14) -> 11 : document number 3, term number 14 appears 11 times etc.."]},{"cell_type":"markdown","metadata":{"id":"mLL85eTS2LDF"},"source":["* It is more efficient to store it that way"]},{"cell_type":"markdown","metadata":{"id":"vjpPajSv2LDF"},"source":["### Viewing Words from our Vocabulary"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"XQS0aMH12LDG","outputId":"f3c7b377-1524-4517-a80c-b1268b7c2a85"},"source":["vocab = vectorizer.get_feature_names(); vocab[5000:5005]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['augers', 'auggie', 'augh', 'aughties', 'augie']"]},"metadata":{"tags":[]},"execution_count":78}]},{"cell_type":"markdown","metadata":{"id":"1IYCsG6v2LDJ"},"source":["### Splitting our document and Creating Unique set"]},{"cell_type":"markdown","metadata":{"id":"NErPVt3D2LDJ"},"source":["* Tokenizer will not split that way but if we just split it by space it will be like"]},{"cell_type":"code","metadata":{"collapsed":true,"id":"qcD8qkc22LDK","outputId":"f266c7b5-629b-4a03-bcc0-0887d607545f"},"source":["w0 = set([o.lower() for o in trn_x[0].split(' ')]); w0"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'a',\n"," 'absurd',\n"," 'an',\n"," 'and',\n"," 'audience',\n"," 'be',\n"," 'better',\n"," 'briefly.',\n"," 'by',\n"," 'can',\n"," 'chantings',\n"," 'cinematography',\n"," 'comedy.',\n"," 'crazy',\n"," 'cryptic',\n"," 'dialogue',\n"," 'easy',\n"," 'era',\n"," 'even',\n"," 'eventually',\n"," 'example',\n"," 'feelings',\n"," 'for',\n"," 'formal',\n"," 'forrest',\n"," 'frederic',\n"," 'from',\n"," 'future',\n"," 'general',\n"," 'good',\n"," 'grader.',\n"," 'great',\n"," 'has',\n"," 'insane,',\n"," 'into',\n"," 'is',\n"," 'it',\n"," \"it's\",\n"," 'just',\n"," 'kirkland',\n"," 'level',\n"," 'make',\n"," 'making',\n"," 'man',\n"," 'might',\n"," 'mob',\n"," 'narrative',\n"," 'no',\n"," 'of',\n"," 'off',\n"," 'off.',\n"," 'on',\n"," 'opening',\n"," 'orchestra',\n"," 'out',\n"," 'pig.',\n"," 'putting.',\n"," 'sally',\n"," 'scene',\n"," 'seem',\n"," 'seen',\n"," 'shakespeare',\n"," 'should',\n"," 'singers.',\n"," 'some',\n"," 'stars',\n"," 'starts',\n"," 'stays',\n"," 'story',\n"," 'technical',\n"," 'terrific',\n"," 'than',\n"," 'that',\n"," 'the',\n"," 'think',\n"," 'third',\n"," 'those',\n"," 'time',\n"," 'to',\n"," 'too',\n"," 'turned',\n"," 'unfortunately',\n"," 'unnatural',\n"," 'vilmos',\n"," 'violent',\n"," 'who',\n"," 'whole',\n"," 'with',\n"," 'would',\n"," 'you',\n"," 'zsigmond.'}"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"markdown","metadata":{"id":"ZMzZINqD2LDP"},"source":["### Viewing vectorized document 1"]},{"cell_type":"markdown","metadata":{"id":"jlj7uhUh2LDQ"},"source":["* Only 93 of the 75780 elements were used in this document"]},{"cell_type":"code","metadata":{"id":"kfWU-YFY2LDQ","outputId":"588404b1-58aa-4e1b-b1fb-bf6d6fcec676"},"source":["trn_term_doc[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<1x75780 sparse matrix of type '<class 'numpy.int64'>'\n","\twith 93 stored elements in Compressed Sparse Row format>"]},"metadata":{"tags":[]},"execution_count":79}]},{"cell_type":"code","metadata":{"id":"FX8I5iIJ2LDX","outputId":"548f0d4c-db09-467e-d77e-89b29c702589"},"source":["# index of \"absurd\"\n","vectorizer.vocabulary_['absurd']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1311"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"id":"YJxLA-UA2LDc","outputId":"ae83af07-be01-47f3-d9e4-eb7f1895e415"},"source":["trn_term_doc[0,1311]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"code","metadata":{"id":"j6lZwxIS2LDf","outputId":"bd50813b-6e7d-432e-cb1b-121f47c633bd"},"source":["trn_term_doc[0,5000]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{"tags":[]},"execution_count":84}]}]}